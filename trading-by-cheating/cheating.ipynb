{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>-21</th>\n",
       "      <th>-20</th>\n",
       "      <th>-19</th>\n",
       "      <th>-18</th>\n",
       "      <th>-17</th>\n",
       "      <th>-16</th>\n",
       "      <th>-15</th>\n",
       "      <th>-14</th>\n",
       "      <th>-13</th>\n",
       "      <th>...</th>\n",
       "      <th>-6</th>\n",
       "      <th>-5</th>\n",
       "      <th>-4</th>\n",
       "      <th>-3</th>\n",
       "      <th>-2</th>\n",
       "      <th>-1</th>\n",
       "      <th>0</th>\n",
       "      <th>LONG</th>\n",
       "      <th>NETUAL</th>\n",
       "      <th>SHORT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41806</td>\n",
       "      <td>-0.008503</td>\n",
       "      <td>0.014758</td>\n",
       "      <td>0.011849</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>0.011297</td>\n",
       "      <td>0.018726</td>\n",
       "      <td>-0.002589</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002749</td>\n",
       "      <td>0.016001</td>\n",
       "      <td>0.005870</td>\n",
       "      <td>-0.004138</td>\n",
       "      <td>-0.016727</td>\n",
       "      <td>-0.010944</td>\n",
       "      <td>0.010079</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41807</td>\n",
       "      <td>0.014141</td>\n",
       "      <td>0.011419</td>\n",
       "      <td>0.003924</td>\n",
       "      <td>-0.002749</td>\n",
       "      <td>0.016001</td>\n",
       "      <td>0.005870</td>\n",
       "      <td>-0.004138</td>\n",
       "      <td>-0.016727</td>\n",
       "      <td>-0.010944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016001</td>\n",
       "      <td>0.005870</td>\n",
       "      <td>-0.004138</td>\n",
       "      <td>-0.016727</td>\n",
       "      <td>-0.010944</td>\n",
       "      <td>0.010079</td>\n",
       "      <td>-0.001302</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41808</td>\n",
       "      <td>0.011419</td>\n",
       "      <td>0.003924</td>\n",
       "      <td>-0.002749</td>\n",
       "      <td>0.016001</td>\n",
       "      <td>0.005870</td>\n",
       "      <td>-0.004138</td>\n",
       "      <td>-0.016727</td>\n",
       "      <td>-0.010944</td>\n",
       "      <td>0.010079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005870</td>\n",
       "      <td>-0.004138</td>\n",
       "      <td>-0.016727</td>\n",
       "      <td>-0.010944</td>\n",
       "      <td>0.010079</td>\n",
       "      <td>-0.001302</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41809</td>\n",
       "      <td>0.003924</td>\n",
       "      <td>-0.002749</td>\n",
       "      <td>0.016001</td>\n",
       "      <td>0.005870</td>\n",
       "      <td>-0.004138</td>\n",
       "      <td>-0.016727</td>\n",
       "      <td>-0.010944</td>\n",
       "      <td>0.010079</td>\n",
       "      <td>-0.001302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004138</td>\n",
       "      <td>-0.016727</td>\n",
       "      <td>-0.010944</td>\n",
       "      <td>0.010079</td>\n",
       "      <td>-0.001302</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>-0.003472</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41810</td>\n",
       "      <td>-0.002749</td>\n",
       "      <td>0.016001</td>\n",
       "      <td>0.005870</td>\n",
       "      <td>-0.004138</td>\n",
       "      <td>-0.016727</td>\n",
       "      <td>-0.010944</td>\n",
       "      <td>0.010079</td>\n",
       "      <td>-0.001302</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016727</td>\n",
       "      <td>-0.010944</td>\n",
       "      <td>0.010079</td>\n",
       "      <td>-0.001302</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>-0.003472</td>\n",
       "      <td>-0.010342</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Date       -21       -20       -19       -18       -17       -16  \\\n",
       "0  41806 -0.008503  0.014758  0.011849  0.000198  0.002646  0.001583   \n",
       "1  41807  0.014141  0.011419  0.003924 -0.002749  0.016001  0.005870   \n",
       "2  41808  0.011419  0.003924 -0.002749  0.016001  0.005870 -0.004138   \n",
       "3  41809  0.003924 -0.002749  0.016001  0.005870 -0.004138 -0.016727   \n",
       "4  41810 -0.002749  0.016001  0.005870 -0.004138 -0.016727 -0.010944   \n",
       "\n",
       "        -15       -14       -13  ...        -6        -5        -4        -3  \\\n",
       "0  0.011297  0.018726 -0.002589  ... -0.002749  0.016001  0.005870 -0.004138   \n",
       "1 -0.004138 -0.016727 -0.010944  ...  0.016001  0.005870 -0.004138 -0.016727   \n",
       "2 -0.016727 -0.010944  0.010079  ...  0.005870 -0.004138 -0.016727 -0.010944   \n",
       "3 -0.010944  0.010079 -0.001302  ... -0.004138 -0.016727 -0.010944  0.010079   \n",
       "4  0.010079 -0.001302  0.001086  ... -0.016727 -0.010944  0.010079 -0.001302   \n",
       "\n",
       "         -2        -1         0  LONG  NETUAL  SHORT  \n",
       "0 -0.016727 -0.010944  0.010079     1       0      0  \n",
       "1 -0.010944  0.010079 -0.001302     1       0      0  \n",
       "2  0.010079 -0.001302  0.001086     0       1      0  \n",
       "3 -0.001302  0.001086 -0.003472     1       0      0  \n",
       "4  0.001086 -0.003472 -0.010342     1       0      0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"Date\", axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LONG</th>\n",
       "      <th>NETUAL</th>\n",
       "      <th>SHORT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.426628</td>\n",
       "      <td>0.238252</td>\n",
       "      <td>0.33512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.494689</td>\n",
       "      <td>0.426102</td>\n",
       "      <td>0.47213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              LONG       NETUAL       SHORT\n",
       "count  2426.000000  2426.000000  2426.00000\n",
       "mean      0.426628     0.238252     0.33512\n",
       "std       0.494689     0.426102     0.47213\n",
       "min       0.000000     0.000000     0.00000\n",
       "25%       0.000000     0.000000     0.00000\n",
       "50%       0.000000     0.000000     0.00000\n",
       "75%       1.000000     0.000000     1.00000\n",
       "max       1.000000     1.000000     1.00000"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.iloc[:,:22]\n",
    "y=df.iloc[:,-3:]\n",
    "X.describe()\n",
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-21</th>\n",
       "      <th>-20</th>\n",
       "      <th>-19</th>\n",
       "      <th>-18</th>\n",
       "      <th>-17</th>\n",
       "      <th>-16</th>\n",
       "      <th>-15</th>\n",
       "      <th>-14</th>\n",
       "      <th>-13</th>\n",
       "      <th>-12</th>\n",
       "      <th>...</th>\n",
       "      <th>-9</th>\n",
       "      <th>-8</th>\n",
       "      <th>-7</th>\n",
       "      <th>-6</th>\n",
       "      <th>-5</th>\n",
       "      <th>-4</th>\n",
       "      <th>-3</th>\n",
       "      <th>-2</th>\n",
       "      <th>-1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.000570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.013340</td>\n",
       "      <td>0.013344</td>\n",
       "      <td>0.013342</td>\n",
       "      <td>0.013345</td>\n",
       "      <td>0.013348</td>\n",
       "      <td>0.013346</td>\n",
       "      <td>0.013349</td>\n",
       "      <td>0.013352</td>\n",
       "      <td>0.013342</td>\n",
       "      <td>0.013351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013351</td>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.013347</td>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.013349</td>\n",
       "      <td>0.013347</td>\n",
       "      <td>0.013348</td>\n",
       "      <td>0.013347</td>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.013385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.099607</td>\n",
       "      <td>-0.099607</td>\n",
       "      <td>-0.099607</td>\n",
       "      <td>-0.099607</td>\n",
       "      <td>-0.099607</td>\n",
       "      <td>-0.099607</td>\n",
       "      <td>-0.099607</td>\n",
       "      <td>-0.099607</td>\n",
       "      <td>-0.099607</td>\n",
       "      <td>-0.099607</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099607</td>\n",
       "      <td>-0.099607</td>\n",
       "      <td>-0.099607</td>\n",
       "      <td>-0.099607</td>\n",
       "      <td>-0.099607</td>\n",
       "      <td>-0.099607</td>\n",
       "      <td>-0.099607</td>\n",
       "      <td>-0.099607</td>\n",
       "      <td>-0.099607</td>\n",
       "      <td>-0.099607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.005821</td>\n",
       "      <td>-0.005759</td>\n",
       "      <td>-0.005759</td>\n",
       "      <td>-0.005759</td>\n",
       "      <td>-0.005759</td>\n",
       "      <td>-0.005759</td>\n",
       "      <td>-0.005821</td>\n",
       "      <td>-0.005821</td>\n",
       "      <td>-0.005759</td>\n",
       "      <td>-0.005759</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005759</td>\n",
       "      <td>-0.005759</td>\n",
       "      <td>-0.005753</td>\n",
       "      <td>-0.005753</td>\n",
       "      <td>-0.005753</td>\n",
       "      <td>-0.005759</td>\n",
       "      <td>-0.005821</td>\n",
       "      <td>-0.005821</td>\n",
       "      <td>-0.005821</td>\n",
       "      <td>-0.005821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.007446</td>\n",
       "      <td>0.007470</td>\n",
       "      <td>0.007470</td>\n",
       "      <td>0.007470</td>\n",
       "      <td>0.007514</td>\n",
       "      <td>0.007514</td>\n",
       "      <td>0.007533</td>\n",
       "      <td>0.007533</td>\n",
       "      <td>0.007514</td>\n",
       "      <td>0.007533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007533</td>\n",
       "      <td>0.007533</td>\n",
       "      <td>0.007514</td>\n",
       "      <td>0.007533</td>\n",
       "      <td>0.007514</td>\n",
       "      <td>0.007470</td>\n",
       "      <td>0.007470</td>\n",
       "      <td>0.007470</td>\n",
       "      <td>0.007514</td>\n",
       "      <td>0.007533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.070422</td>\n",
       "      <td>0.070422</td>\n",
       "      <td>0.070422</td>\n",
       "      <td>0.070422</td>\n",
       "      <td>0.070422</td>\n",
       "      <td>0.070422</td>\n",
       "      <td>0.070422</td>\n",
       "      <td>0.070422</td>\n",
       "      <td>0.070422</td>\n",
       "      <td>0.070422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070422</td>\n",
       "      <td>0.070422</td>\n",
       "      <td>0.070422</td>\n",
       "      <td>0.070422</td>\n",
       "      <td>0.070422</td>\n",
       "      <td>0.070422</td>\n",
       "      <td>0.070422</td>\n",
       "      <td>0.070422</td>\n",
       "      <td>0.070422</td>\n",
       "      <td>0.070422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               -21          -20          -19          -18          -17  \\\n",
       "count  2426.000000  2426.000000  2426.000000  2426.000000  2426.000000   \n",
       "mean      0.000545     0.000558     0.000555     0.000557     0.000564   \n",
       "std       0.013340     0.013344     0.013342     0.013345     0.013348   \n",
       "min      -0.099607    -0.099607    -0.099607    -0.099607    -0.099607   \n",
       "25%      -0.005821    -0.005759    -0.005759    -0.005759    -0.005759   \n",
       "50%       0.000673     0.000712     0.000712     0.000712     0.000758   \n",
       "75%       0.007446     0.007470     0.007470     0.007470     0.007514   \n",
       "max       0.070422     0.070422     0.070422     0.070422     0.070422   \n",
       "\n",
       "               -16          -15          -14          -13          -12  ...  \\\n",
       "count  2426.000000  2426.000000  2426.000000  2426.000000  2426.000000  ...   \n",
       "mean      0.000561     0.000559     0.000564     0.000561     0.000567  ...   \n",
       "std       0.013346     0.013349     0.013352     0.013342     0.013351  ...   \n",
       "min      -0.099607    -0.099607    -0.099607    -0.099607    -0.099607  ...   \n",
       "25%      -0.005759    -0.005821    -0.005821    -0.005759    -0.005759  ...   \n",
       "50%       0.000758     0.000752     0.000758     0.000758     0.000763  ...   \n",
       "75%       0.007514     0.007533     0.007533     0.007514     0.007533  ...   \n",
       "max       0.070422     0.070422     0.070422     0.070422     0.070422  ...   \n",
       "\n",
       "                -9           -8           -7           -6           -5  \\\n",
       "count  2426.000000  2426.000000  2426.000000  2426.000000  2426.000000   \n",
       "mean      0.000564     0.000565     0.000565     0.000564     0.000561   \n",
       "std       0.013351     0.013350     0.013347     0.013350     0.013349   \n",
       "min      -0.099607    -0.099607    -0.099607    -0.099607    -0.099607   \n",
       "25%      -0.005759    -0.005759    -0.005753    -0.005753    -0.005753   \n",
       "50%       0.000758     0.000763     0.000763     0.000758     0.000752   \n",
       "75%       0.007533     0.007533     0.007514     0.007533     0.007514   \n",
       "max       0.070422     0.070422     0.070422     0.070422     0.070422   \n",
       "\n",
       "                -4           -3           -2           -1            0  \n",
       "count  2426.000000  2426.000000  2426.000000  2426.000000  2426.000000  \n",
       "mean      0.000549     0.000543     0.000543     0.000547     0.000570  \n",
       "std       0.013347     0.013348     0.013347     0.013350     0.013385  \n",
       "min      -0.099607    -0.099607    -0.099607    -0.099607    -0.099607  \n",
       "25%      -0.005759    -0.005821    -0.005821    -0.005821    -0.005821  \n",
       "50%       0.000712     0.000676     0.000712     0.000752     0.000758  \n",
       "75%       0.007470     0.007470     0.007470     0.007514     0.007533  \n",
       "max       0.070422     0.070422     0.070422     0.070422     0.070422  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Option 1) Deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation,LSTM\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Dense(64) is a fully-connected layer with 64 hidden units.\n",
    "# in the first layer, you must specify the expected input data shape:\n",
    "# here, 20-dimensional vectors.\n",
    "model.add(Dense(64, activation='relu', input_dim=22))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "2183/2183 [==============================] - 1s 539us/step - loss: 1.0896 - acc: 0.3990\n",
      "Epoch 2/18\n",
      "2183/2183 [==============================] - 0s 24us/step - loss: 1.0735 - acc: 0.4288\n",
      "Epoch 3/18\n",
      "2183/2183 [==============================] - 0s 23us/step - loss: 1.0735 - acc: 0.4297\n",
      "Epoch 4/18\n",
      "2183/2183 [==============================] - 0s 22us/step - loss: 1.0711 - acc: 0.4292\n",
      "Epoch 5/18\n",
      "2183/2183 [==============================] - 0s 23us/step - loss: 1.0733 - acc: 0.4297\n",
      "Epoch 6/18\n",
      "2183/2183 [==============================] - 0s 22us/step - loss: 1.0729 - acc: 0.4279\n",
      "Epoch 7/18\n",
      "2183/2183 [==============================] - 0s 23us/step - loss: 1.0721 - acc: 0.4292\n",
      "Epoch 8/18\n",
      "2183/2183 [==============================] - 0s 23us/step - loss: 1.0724 - acc: 0.4292\n",
      "Epoch 9/18\n",
      "2183/2183 [==============================] - 0s 23us/step - loss: 1.0714 - acc: 0.4292\n",
      "Epoch 10/18\n",
      "2183/2183 [==============================] - 0s 24us/step - loss: 1.0711 - acc: 0.4292\n",
      "Epoch 11/18\n",
      "2183/2183 [==============================] - 0s 23us/step - loss: 1.0725 - acc: 0.4292\n",
      "Epoch 12/18\n",
      "2183/2183 [==============================] - 0s 24us/step - loss: 1.0698 - acc: 0.4297\n",
      "Epoch 13/18\n",
      "2183/2183 [==============================] - 0s 23us/step - loss: 1.0718 - acc: 0.4297\n",
      "Epoch 14/18\n",
      "2183/2183 [==============================] - 0s 24us/step - loss: 1.0724 - acc: 0.4283\n",
      "Epoch 15/18\n",
      "2183/2183 [==============================] - 0s 23us/step - loss: 1.0723 - acc: 0.4292\n",
      "Epoch 16/18\n",
      "2183/2183 [==============================] - 0s 22us/step - loss: 1.0707 - acc: 0.4283\n",
      "Epoch 17/18\n",
      "2183/2183 [==============================] - 0s 23us/step - loss: 1.0729 - acc: 0.4292\n",
      "Epoch 18/18\n",
      "2183/2183 [==============================] - 0s 22us/step - loss: 1.0720 - acc: 0.4292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ea11ee6a20>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          epochs=18,\n",
    "          batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_54 to have shape (3,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-9f0f1c121c10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[0;32m   1100\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1102\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    136\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_54 to have shape (3,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0794930585617881, 0.4032921788623794]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  (Option 2) XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_xgb=pd.DataFrame({\"Classes\":y_train[\"LONG\"]*0+y_train[\"NETUAL\"]*1+y_train[\"SHORT\"]*2})\n",
    "y_test_xgb=pd.DataFrame({\"Classes\":y_test[\"LONG\"]*0+y_test[\"NETUAL\"]*1+y_test[\"SHORT\"]*2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data=X_train, label=y_train_xgb)\n",
    "dtest = xgb.DMatrix(data=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {\n",
    "    'max_depth': 6,\n",
    "    'objective': 'multi:softmax',  # error evaluation for multiclass training\n",
    "    'num_class': 3,\n",
    "    'n_gpus': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.train(params, dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.71      0.53       100\n",
      "           1       0.33      0.09      0.14        56\n",
      "           2       0.37      0.25      0.30        87\n",
      "\n",
      "   micro avg       0.40      0.40      0.40       243\n",
      "   macro avg       0.37      0.35      0.32       243\n",
      "weighted avg       0.38      0.40      0.36       243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[71,  5, 24],\n",
       "       [37,  5, 14],\n",
       "       [60,  5, 22]], dtype=int64)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalized=True, cmap='bone'):\n",
    "    plt.figure(figsize=[7, 6])\n",
    "    norm_cm = cm\n",
    "    if normalized:\n",
    "        norm_cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        sns.heatmap(norm_cm, annot=cm, fmt='g', xticklabels=classes, yticklabels=classes, cmap=cmap)\n",
    "        plt.savefig('confusion-matrix.png')\n",
    "\n",
    "plot_confusion_matrix(cm, ['LONG', 'NETUAL', 'SHORT'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
